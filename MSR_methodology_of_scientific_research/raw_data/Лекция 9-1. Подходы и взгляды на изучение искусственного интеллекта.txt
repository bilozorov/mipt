Здравствуйте, дорогие друзья! Сегодня у нас в центре внимания система искусственного интеллекта и тема сегодняшней лекции – подходы и взгляды на изучение искусственного интеллекта. Мы рассмотрим с вами два основных вопроса. Во-первых,

философско-методологические проблемы искусственного интеллекта, основные направления развития ИИ, символьный и нейросетевой. И второй вопрос. Немного поговорим о Джеффри Хинтоне, его концепции глубокого обучения, а также о том, к чему может привести неконтролируемое или контролируемое развитие системы искусственного интеллекта, вот так называемой концепции технологической сингулярности.

Так что же это – миф или реальность? Первый вопрос – философско-методологические предпосылки развития системы искусственного интеллекта. Ну, конечно, никакого бы искусственного интеллекта не было, если не были бы созданы универсальные цифровые вычислительные машины, вычислительная техника.

Здесь история достаточно долгая, глубокая. Первые идеи создания механической цифровой вычислительной машины реализовал в 1623 году немецкий механик-изобретатель Вильгельм Шикард. Далее последовали цифровые машины Блеза Паскаля,

замечательного математика и философа, это 1643 год, и другого философа, математика и логика, Готфрида Вильгельма Либница, 1671 год. Кстати, Либниц впервые описал современную двоичную систему счисления, хотя до него этой системой периодически увлекались многие великие учёные. Кроме того, Либниц предложил очень важную

для дальнейшего развития вычислительной техники концепцию вычисления истины, вычисления мысли. Лебнец считал, что любая правильная мысль с алгебраической точки зрения – это результат реализации правильной процедуры вычисления. Согласимся, что эта идея в дальнейшем в истории вычислительной техники, искусственного интеллекта имела очень большое значение. Ну и, наконец, в XIX веке

англичане, механик-изобретатель Чарльз Беббидж и знаменитая женщина, первый программист в истории, создатель первой программы Ада Лавлис, работали над программируемой уже механической вычислительной машиной, которая должна была уметь решать дифференциальные уравнения. Кстати, скажем, что

В итоге Бэббидж после многих лет непрестанных трудов так окончательный вариант механической вычислительной машины или, как он её называл, разносной машины не построил, но зато Ада Лавлис смогла разработать основные принципы, лежащие в основе современной теории и практики программирования.

Ну и, наконец, пришёл черёд электроники, электронным устройством в вычислительной технике. Здесь огромный шаг вперёд сделал замечательный немецкий изобретатель Конрад Цузе. Он разработал несколько программно-управляемых цифровых компьютеров, начиная с 1941 года, в том числе

вполне современную машину Z4. Это 1944-1945 годы. К сожалению, дальнейшие работы ЦУЗа были прекращены в связи с падением гитлеровской Германии. Тем не менее, американские создатели машины ИНИАК первого программируемого крупного вычислительного комплекса в 1946-1947 году во многом воспользовались наработками Конрада ЦУЗа. Техническая база

для разработки и развития системы искусственного интеллекта, будем считать, что она подготовлена. Впереди, конечно, переход от ламповых компьютеров к компьютерам, основанным на полупроводниковых элементах, затем на интегральных микросхемах, на современных чипов. Но, в принципе, идея уже реализуется, да, и техническая база уже готова. Теперь дело за

математиками, философами, программистами. Здесь в развитии вопросов, связанных с искусственным интеллектом, огромное значение имел так называемый семинар Дартмутского колледжа. Он произошёл в Великобритании летом 1956 года. Это был двухмесячный научный семинар, на котором впервые систематически полноценно были обсуждены вопросы, связанные с созданием искусственного интеллекта. Идея была такая.

Можно ли смоделировать человеческий разум путём реализации определённых вычислительных процедур? Ну и здесь встретились те люди, которые, собственно, и стали основоположником новой науки, науки об искусственном интеллекте. Это Джон Маккарти, Марвин Мински, Клод Шеннон и Натаниэль Рочестер. Джон Маккарти не только предложил сам термин «искусственный интеллект»,

но и сформулировал первый ключевой тезис науки об искусственном интеллекте. Здесь он приведен в полном виде на слайде. Обычное человеческое умственное действие является синтезом множественного, множества более мелких операций, производимых нашим мозгом в ответ на среду. И, что самое главное, эту процедуру можно сымитировать.

Основное условие всех подобных операций, согласно Маккарти, заключается в том, что любое вычисление, если мы говорим о машине, или говоря в целом, любое перемещение, преобразование информации происходит в изменчивой непредсказуемой среде. То есть, собственно, искусственный интеллект отличается от обычных вычислительных процедур, реализуемых в обычном компьютере,

Прежде всего тем, что вокруг системы искусственного интеллекта происходит множество непредсказуемых изменений. Есть непредсказуемая изменчивая среда. И в этом смысле тезис Маккарти продолжается тезисом Марвина Мински, ещё одного из создателей науки об искусственном интеллекте. Нужно разработать машину, которая бы демонстрировала определённый вид обучения.

Обратите внимание, здесь впервые вместо слова понятие программирование используется понятие обучение. В этом один из основных концептуальных сдвигов от обычных компьютеров к системам искусственного интеллекта. Такая машина должна быть снабжена входным и выходным каналами, то есть средствами обеспечения разнообразных выходных ответов на входящие вопросы.

Такой метод обучения можно назвать метод проб и ошибок, то есть процесс приобретения диапазона вариантов ввода-вывода функций. Дальше Минский продолжает. Машина запрограммированная таким образом при помещении в соответствующую изменчивую среду и с учетом критериев провал или успешное достижение цели может быть обучена проявлять целенаправленное поведение.

Итак, Маккарти и Минский говорят об обучении машины в проявлении определенного целенаправленного поведения. С их точки зрения это и есть то, что отличает искусственный интеллект от обычной системы вычислительных процедур. Но дальше развитие пошло двумя способами развития системы искусственного интеллекта.

Сотрудники и участники Дармотского колледжа, семинара Дармотского колледжа, они говорили о том, что сложные интеллектуальные действия надо раскладывать на сумму простых логических операций. Это так называемый символный, логический подход к моделированию искусственного интеллекта. Есть и другой. Можно попытаться сымитировать деятельность коры головного мозга.

так называемый нейросетевой подход, то есть моделирование взаимодействия нейронов, так как это происходит в реальной ситуации в нашем биологическом субстракте, в головном мозге. Вот в логике этого второго подхода в 1943 году произошло очень важное событие, которое

в рамках нейросетевого подхода считается основополагающим, и до сих пор в статье «Логическое исчисление идей, относящихся к нервной активности» Орен Маккалок и Олтер Питтс предложили понятие искусственной нейронной сети.

В частности, вот именно в этой работе им была предложена модель искусственного нейрона. Дальше физиолог Дональд Хепп в работе «Организация поведения 1949 год» описал основные принципы обучения нейронов. Оказывается, что нейронная сеть также может не просто программироваться, она может реально обучаться на

внешней среде, на внешних задачах. Ну и чуть позже, несколько лет спустя, эти идеи развил замечательный американский нейрофизиолог, заметьте, всё это физиологи, да, это не совсем информатики, не совсем математики, а именно нейрофизиологи, прежде всего, Франк Розенблат, который предложил схему устройства, моделирующего процесс человеческого восприятия. Это устройство он назвал перцептроном. Ну, собственно, во всех первых учебниках

посвящённых теории искусственного интеллекта и нейросетевому подходу как раз в качестве первого примера приводится перцептрон Розенблата и его дальнейшие модификации. Ну, ключевой вопрос, конечно, интересующий всех, кто слышит об искусственном интеллекте – может ли машина мыслить? Этот вопрос поставлен

английским математикам, великим английским математикам, одним из основоположников современной информатики Аланом Тьюрингом в 1950-м году в его работе «Вычислительные машины и разум». Именно в этой работе Тьюринг предложил свой знаменитый тест Тьюринга на определение интеллектуальных способностей вычислительного устройства.

Мы к нему чуть позже обратимся. Клод Шеннон, замечательный американский инженер и математик, вы знаете, что это один из основоположников современной теории информации, был настолько уверен в реализуемости машинного искусственного интеллекта, что на вопрос, может ли машина мыслить, он отвечал, ну мы же мыслим.

То есть имелось в виду, что человек это тоже машина, это тоже вычислительное устройство. Если человек как механизм, ну пусть биологический, но механизм мыслит, то почему же это нельзя сымитировать, нельзя реализовать этот процесс в какой-либо вычислительной машине. Кстати говоря, наш великий физик, академик Лев Давыдович Ландау, это уже не анекдот,

а реальная история. На тот же самый вопрос, обращенный к нему в 1961 году на физтехе его студентом, я знаю этого бывшего студента и знаю эту историю с его слов, когда он подошел к Леву Давыдовичу, спросил, ну вот я очень интересуюсь проблемами искусственного интеллекта, как вы думаете, Лев Давыдович, может ли машинам мыслить? Ландау сказал,

Молодой человек, не говорите ерунды. Люди-то не мыслят, а вы хотите, чтобы машины мыслили. Понимаете? Вот два диаметрально противоположных ответа на один и тот же вопрос. То есть для Шеннона важно, что есть механизм, который мыслит, значит этот механизм можно иметь. При этом Шеннон, обратите внимание, он сам процесс мышления предполагает совершенно понятным. То есть это то, что делает человек, любой.

А Ландау, со свойственной ему парадоксальностью, да, он смотрит в корень, он видит главное. А что есть мышление? То, что мы называем человеческим мышлением, это то самое, это подлинное мышление или не совсем? А тогда о какой имитации мышления подлинного можно говорить? Прежде всего разобраться с самим процессом мышления. Но это и есть главный на самом деле философский вопрос всей проблематики искусственного интеллекта.

Что же такое мышление? Что же имитирует искусственный интеллект? И даже если мы сымитируем какой-либо вычислительной системой человеческий интеллект, значит ли это, что мы поняли, как мы реально думаем в нашей голове? Ну, дальше я ещё раз вернусь к этому вопросу в конце нашей лекции.

Значит, в теории и истории искусственного интеллекта возникли две точки зрения, так называемая гипотеза сильного ИИ и гипотеза слабого ИИ. Ну, чем они отличаются друг от друга? Термин «сильный искусственный интеллект» ввёл

Кстати, большой противник этого понятия – британский философ Джон Сёрль. По его мнению, программа, обладающая сильным искусственным интеллектом, будет не просто моделью разума, она в буквальном смысле слова сама и будет разумом, в том же смысле, в котором человеческий разум – это разум.

То есть сильный ИИ, как его определяет Сёрль, — это сам разум. То есть машина внезапно приобрела все когнитивные способности человека в буквальном смысле. Слабый ИИ, слабый искусственный интеллект — это

программа, которая может имитировать или моделировать, если угодно, отдельные способности человека, отдельные когнитивные возможности. Ну, например, переводить тексты, переводить с одного языка на другое, распознавать речь, играть в шахматы, может быть, даже доказывать какие-то математические теоремы. Но всё равно набор этих когнитивных функций у слабого искусственного интеллекта достаточно

ограничен. В полемике о возможности создания сильного искусственного интеллекта, а Сёрль полагает, что создать его невозможно, слабый, да, но не сильный, сталкиваются два знаменитых мысленных эксперимента. Это тест Тьюринга и эксперимент «Китайская комната», который предложил Сёрль.

Но эксперимент «Китайская комната» — это эксперимент, предложенный Мыслиной в 1880 году и имеющий огромную традицию не только поддержки, но и огромную традицию критики. Ну, я думаю, что почти все, кто слушает эту лекцию или смотрит её, знают, в принципе, что такое тест Йоринга.

Да, это когда человеку и машине задаются одни и те же вопросы третьей стороной, да, и в какой-то момент времени уже отличить ответы человека от ответы машины, от ответов искусственного интеллекта уже невозможно. Но при этом предполагается, что конечное число шагов задействовано, это очень важная

дополнения. То есть понятно, что если предположить, что количество попыток стремится к бесконечности, количество вопросов, обращенных к машине, стремится к бесконечности, то с учетом обучаемости искусственного интеллекта, не будем еще про это забывать, то тест Тьюринга, скорее всего, всегда будет искусственным интеллектом пройден. Но если количество шагов конечно, количество вопросов, то действительно, тест Тьюринга — это инструмент, который позволяет отличить

сильный искусственный интеллект, сказать, что он есть. Я не могу отличить его от человеческого разума. А вот теперь эксперимент «Китайская комната». Смысл его следующий. В некой закрытой комнате сидит человек, который не знает китайского языка и не знает ни одного иероглифа.

У него есть огромная стопка иероглифов перед ним и подробная инструкция, в каком случае какой иероглиф с каким нужно соединять, какую дощечку класть рядом с другой дощечкой. То есть у него есть специальная книга с самыми подробными инструкциями. На вход, то есть входное окошко, подаются таблички с иероглифами. Это вопросы.

подаёт таблички человек, который знает китайский язык, знает смысл иероглифов. Ещё раз повторяю, что человек, оперирующий иероглифами внутри комнаты, не знает ни одного иероглифа и ни одного слова по-китайски. Значит, получив вопрос, то есть некий иероглиф,

табличку с иероглифами. Вот этот внутренний человек внутри китайской комнаты открывает инструкцию и видит, что если появилась вот такая табличка на входе, надо взять такую-то и такую-то табличку из топки, лежащей перед ним на столе, и соединить их вместе друг с другом. Потом соединенные две таблички передать на выход.

На выходе тоже сидит человек, который знает китайский язык и вполне осмысленно читает, что получилось. Ну, естественно, что можно себе представить, что вот этот внутренний человек в китайской комнате, он соединяет между собой очень большое количество иероглифов, читая инструкции в книге, но при этом не понимает ни одного иероглифа.

Этот человек в китайской комнате похож на сильный искусственный интеллект? Он может пройти тест Тьюринга, не зная ни одного реального иероглифа, не понимая, что он делает? Конечно, может, но является ли он действительно

по-настоящему аналогом или моделью человеческого разума? Конечно, нет, потому что ничего не понимает в том, что он делает. То есть, видите, тест Юринга проходится на китайском языке, но является ли такой

субъект, такая китайская комната с сильным искусственным интеллектом, конечно, нет. Ну, я сразу скажу, что эксперимент Сёрли много раз критиковали, искали в нем слабые места, как бы дыры искали в этом эксперименте, но в то же время ни одна сейчас

серьезная философская работа, посвященная сильному искусственному интеллекту, возможности его создания мимо либо самого эксперимента Сёрли, либо мимо его каких-то аналогов, обсуждений пройти не может. Ну и вот аргументация против сильного искусственного интеллекта по Сёрли. Первый шаг. Если гипотеза сильного ИИ верна,

Тогда существует такая программа для китайской письменности, при запуске которой в вычислительной системе эта система будет понимать китайскую письменность. Но в то же время, второй шаг, я могу исполнить программу для китайской письменности без понимания этой письменности.

только имея соответствующие инструкции, процедур, описание процедур соединения между собой отдельных иероглифов. Следовательно, гипотеза сильного ИИ, то есть как искусственного интеллекта, буквально дождественного человеческому разуму, обладающему обязательно пониманием

а не только инструкциями по соединению каких-то знаков системы. Следовательно, гипотеза сильного И, по мнению Сёрли, неверна. Ну, кстати говоря, аргумент

или эксперимент китайской комнаты, он далеко не новый. Ещё Лейбнец предлагал рассмотреть вот эту гигантскую мельницу. Почему мельница Лейбнеца? Это потому что во времена самого Лейбнеца, в конце 17 века, мельницы были, во-первых, самым распространённым механизмом,

который был доступен человеческому взгляду, мельницы были везде. А во-вторых, были мельницы довольно сложные с точки зрения своего технического устройства. Поэтому мельницы часто использовались в качестве, ну, таких универсальных механизмов.

как модель механистического подхода в целом. Ну вот мельница-лейбница, там вращаются разные детали, это наш разум. Давайте представим, что разум – это вот такая гигантская мельница, всё в ней работает, всё соединено, всё выполняет свои функции. Но где здесь разум?

Где он содержится? Где то, что обеспечивает понимание нашей мысли внутри этой мельницы? Есть только вход и выход. На входе – зерно, на выходе – мука. Где же появляется мысль как таковая? Мысль, понимаемая самим разумом. Бумажная машина Дьюринга – это машинный алгоритм для игры в шахматы. Дьюринг его в том же 1951 году придумал.

тоже работающая как квази-интеллектуальная система, отрабатывающая все алгоритмы игры в шахматы, но не являющаяся системой, которая понимает, что она делает. Ну и, наконец, предтеча, обращаю ваше внимание, эксперимента «Китайская комната», это предложенный Недом Блоком еще в 1978 году, за два года до Серля, эксперимент мысленно «Китайская нация».

Он схож с китайской комнатой, но в большей степени похож на моделирующую разум нейронную сеть. Это скорее вот к нейросетевому подходу. В нем тысячи китайцев соединены телефонными проводами друг с другом и должны звонить следующему абоненту, получив определенное количество звонков на вход своей комнаты, маленькой ячейки, в котором каждый китаец

находится. То есть каждый китайцы имитирует искусственный нейрон, эмулирует нейрон, при этом не передавая, собственно, никакого, не понимая никакое содержание. Он отдельный нейрон, не является носителем содержательной стороны коммуникации. Ну и естественно, что блок делает тот же самый вывод, что мы видим огромное количество сигналов, двигающихся по каким-то правилам, но ни в одном из этих сигналов нет смысла.

Ни один из этих сигналов, ни один из этих нейронов не понимает, что он делает. Итак, друзья мои, два подхода к созданию искусственного интеллекта мы с вами сформулировали. Во-первых, так называемый нисходящий или формально-логический.

когда мы моделируем мыслительные операции средствами формальной логики сверху вниз. Берем большую мыслительную операцию и раскладываем ее на сумму небольших логических процедур, которые можно уже

эмулировать или моделировать вычислительными средствами. И второй подход, так называемый нейросетевой, или его называют по-другому восходящий, когда мы непосредственно моделируем нейронную активность мозга. Ну, с помощью этого подхода, в частности, на сегодняшний день,

смоделировано компьютерное зрение, но и реализуется система глубокого обучения. Чуть позже о работах Джеффри Хинтона мы с вами поговорим. Итак, нейросетевой подход. Что такое формальный нейрон? Я думаю, что многие знают. Ячейка нейрона – это тело, реализующее функцию активации. В это тело поступают входные сигналы,

Входные сигналы умножаются на определенные весовые коэффициенты. Выбор этих весовых коэффициентов W1, W2, W3, Wn — это, собственно, вопрос, связанный с обучением нейрона. Нейрон суммирует

входные сигналы, умноженные на весовые коэффициенты, и в случае, если эта сумма превышает некое пороговое значение, которое тоже является элементом обучения нейрона, передается выходной сигнал.

выходной сигнал Y. Дальше он идёт к следующим нейронам, к одному или нескольким, и с ним дальше с этим сигналом происходит то же самое, что на первоначальном нейроне. Ну вот, собственно, первая нейронная сеть с так называемой прямой связью, самая простая. Вы видите, что здесь несколько внутренних слоёв, связанных друг с другом. Именно такие нейронные сети с прямой связью, они, собственно, были основой первых

систем восприятия перцептрона розенблата. Вот такая система как раз была реализована. Есть более сложные, так называемые рекуррентные нейронные сети, ну самая известная так называемая сеть Хопфилда, в которой выходные сигналы нейронов

являются сигналами обратной связи для самих нейронов. Причем есть еще промежуточные звенья в виде определенных элементов памяти. Такая сеть с обратной связью, она обладает способностью стремиться к определенному устойчивому состоянию.

что очень важно в задачах, в том числе, глубокого обучения. Мы чуть позже об этом специально поговорим. Сейчас в системах моделирования искусственного интеллекта как раз чаще используются именно рекуррентные нейронные сети, в частности, сеть Хопфилда. Естественно, что давайте для сравнения посмотрим, обсуждая вопрос, насколько действительно искусственные нейроны, искусственные нейронные сети

моделируют естественные человеческие нейронные сети. Давайте посмотрим на эту картинку, на которой изображен человеческий нейрон, нейрон коры головного мозга. Здесь внешне всё очень похоже. Вы видите, что тело нейрона, которому подходят входные сигналы в виде так называемых дендритов,

Дальше нейрон суммирует эти сигналы, суммирует сигналы, причём, опять же, умножая их на некие весовые коэффициенты. Выбор их – это вопрос сложный, до сих пор до конца не прояснённый. И в случае превышения суммы определённого порогового значения передаёт сигнал дальше по длинному нейрону, называемому аксоном. Ну, вокруг него ещё всякие клетки,

специальные перетяжки, внешняя среда, которая тоже на аксон определенным образом влияет. Аксон может разделяться, опять же, на несколько кусочков, вы видите на выходе, на выходные концы аксона, и вот здесь еще присутствуют так называемые синаптические контакты.

потому что с дендритами другого нейрона вот эти окончания аксона, разветвлённые, не напрямую соединяются, как вы знаете, а разрываются. Есть разрыв, так называемая синаптическая щель или синаптический контакт, в которой передача информации от одного синапса к другому осуществляется не электрически, а с помощью химических веществ.

То есть пузырьки в одной части контакта должны освободить определённые так называемые нейромедиаторы, их большое количество, самых разных, и этот нейромедиатор должен быть уловлен нейрорецептором у второй стороны синаптического контакта. Тогда произойдёт возбуждение.

произойдет передача соответствующего электрического импульса. То есть, вы видите, что в человеческой нейронной сети есть, ну, по сути, две разные системы передачи информации. Есть электрическая и есть довольно сложная химическая, потому что количество этих

нейромедиаторов, их разные виды, их разные модификации, количество этих нейрорецепторов, работающих, не работающих, оно поистине огромно. Ну, собственно, вся фармакология, то есть все психоактивные вещества, воздействующие на человеческое сознание, они прежде всего работают с этими рецепторами.

То есть, прежде всего, всё направлено на синаптическую щель, на синаптический контакт, а не на электрическое возбуждение аксона или дендритов. Действительно, мы можем сказать, что нейронные сети имитируют работу

нейронных сетей, коры головного мозга, они способны к обучению. То есть их не надо программировать в классическом смысле этого слова. Это похоже на обучение человека. Однако, с другой стороны, человеческие нейроны гораздо сложнее устроены, поскольку это биохимические объекты. Во-вторых,

На биологические нейронные сети, как сейчас выясняется, огромное влияние, даже незначительное, а огромное оказывают иные отделы мозга.

не только кора, это гиппокам, таламус, гиппоталамус, то есть в целом получается слишком сложная система для того, чтобы мы могли сказать, что вот мы получили какую-то средствами нейросетевого подхода имитацию человеческой нейронной сети. Ну и самое главное,

Что надо ещё упомянуть? Человек — это не вычислительное устройство, которое стоит в углу большой комнаты. Вы подходите к нему, набираете какие-то данные или подключаете какие-то данные, что-то внутри происходит, и вы получаете выходную информацию, считываете её, записываете и уносите с собой. Человек — это часть огромного мира. Его сознание, его мышление встроено в окружающую среду.

вмонтировано в конкретную ситуацию окружающей действительности. И не только здесь и сейчас, но во всю историю, если угодно, человеческой культуры. То есть сознание всегда ситуационно, социально, культурно, исторически детерминировано. Как ни странно, сейчас, ребят, нейробиологи всё больше приходят к этой мысли.

Ну, те люди, которые пытались, прежде всего, реализовать нейросетевой подход. Вот всё можно объяснить взаимодействием нейронов. Сейчас становится понятно даже таким заточенным под нейросетевой подход нейробиологам, нейрофизиологам, что этого недостаточно, что надо учитывать среду, надо учитывать взаимодействие человека с другими людьми, надо учитывать механизмы коммуникации, взаимодействие человека с человеком.

Но могу сказать, что нейробиологи пришли к этому буквально только сейчас, в последние годы, даже, можно сказать, в последние месяцы. А те же самые когнитивные психологи, есть такое направление в современной психологии, причем те, которые занимаются экспериментальной практикой, то есть экспериментально,

изучают сознание человека, они уже лет 40, по крайней мере, как перестали рассматривать человека как вот такое изолированное отдельное вычислительное устройство. Они уже давно говорят о встроенном ситуативном сознании, о том, что невозможно отделить человека от окружающего мира и от других людей. Уже по-другому

в том числе и с экспериментальной точки зрения, человека и не рассматривают. То есть даже сейчас уже нейробиология отстаёт от достижений буквально смежной области, когнитивной психологии. Можно сказать, что даже если в какой-то момент сильный ИИ, сильный искусственный интеллект, допустим,

с помощью нейронной сети, искусственной нейронной сети, будет реализован, он пройдет тест Юринга и будет всегда его проходить, это вовсе не означает, друзья мои, давайте не будем делать этой методологической ошибки, что мы, вот поэтому мы поняли, как в реальности люди мыслят.

моделирование мышления средствами искусственного интеллекта и сам процесс мышления, всё-таки это очень большие разные вещи. Тем более, что нам ещё, как нас просил сделать Лев Давыдов и Сландау, нам ещё предстоит разобраться, что есть мышление, как мыслит человек.

